---
title: "Hw1"
author: "Group 43, Pezone, Sampieri"
date: "29 October 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
```
# Part 1

## Simulations
Start by assuming the two players pick their sequences completely at random.



```{r}
set.seed(1234)
N = 1000
n = 1000
#0=RED CARD     1=BLACK CARD

winP1 = 0
winP2 = 0
draw = 0

deck = c(rep(1,26), rep(0,26))

#SIMULATION

for (i in 1:N){
  
  #player choices
  cardsP1 = sample(0:1,size=3,rep=T)
  cardsP2 = sample(0:1,size=3,rep=T)
  
  #Shuffled deck
  deck = sample(deck,size=52,rep=F) #vettore mischiato
  
  #counter of point for a single game
  c1 = 0 
  c2 = 0
  k = 4
  
  #pick the first 3 card
  sq = c()
  for(i in 1:3){sq[i] = deck[i]}
  
  #picke the other from 4 to 52
  while (k>3 && k<length(deck)-3){
    if(sq[1] == cardsP1[1] && sq[2] == cardsP1[2] && sq[3] == cardsP1[3] ){   #SEQUENCE = PLAYER1???
      c1 = c1+1
      
      sq[1] = deck[k+1]
      sq[2] = deck[k+2]
      sq[3] = deck[k+3]
      k = k+3
      }
    else if(sq[1] == cardsP2[1] && sq[2] == cardsP2[2] && sq[3] == cardsP2[3]){    ##SEQUENCE = PLAYER2???
      c2 = c2+1
      
      sq[1] = deck[k+1]
      sq[2] = deck[k+2]
      sq[3] = deck[k+3]
      k = k+3
    }
    else {
    
    #I go ahead with the cards 
    sq[1] = sq[2]
    sq[2] = sq[3]
    sq[3] = deck[k]
    k = k+1
    }
  }   
  #Ant the winne is.....?
  if (c1>c2){
    winP1=winP1+1}
  if(c2>c1){
    winP2=winP2+1}
  if(c2==c1){
    draw=draw+1}
}
cat('P_player1 = ',winP1/(winP1+winP2+draw),'\nP_player2 = ', winP2/(winP1+winP2+draw),'\nP_draw = ',
draw/(winP1+winP2+draw))
```

Now try to see what happen if the Player2 use the trick for a specific pattern.

```{r}
set.seed(1234)
N = 1000
n = 1000
#0=RED CARD     1=BLACK CARD

winP1 = 0
winP2 = 0
draw = 0

#cardsP1 = c(0,0,0) #case1
cardsP1 = c(0,0,1) #case2
#cardsP1 = c(1,0,0) #case3

cardsP2 = c()   #trick
if(cardsP1[2] == 1){cardsP2[1] = 0}
if(cardsP1[2] == 0){cardsP2[1] = 1}
cardsP2[2] = cardsP1[1]
cardsP2[3] = cardsP1[2]


deck = c(rep(1,26), rep(0,26))

#SIMULATION




for (i in 1:N){
  #shuffled deck
  deck=sample(deck,size=52,rep=F) 
  
  #counter of point for a single game
  c1 = 0 
  c2 = 0
  k = 4
  
  #pick the first 3 card
  sq = c()
  for(i in 1:3){sq[i] = deck[i]}
  
  #picke the other from 4 to 52
  while (k>3 && k<length(deck)-3){
    if(sq[1] == cardsP1[1] && sq[2] == cardsP1[2] && sq[3] == cardsP1[3] ){   #SEQUENCE = PLAYER1???
      c1 = c1+1
      
      sq[1] = deck[k+1]
      sq[2] = deck[k+2]
      sq[3] = deck[k+3]
      k = k+3
      }
    else if(sq[1] == cardsP2[1] && sq[2] == cardsP2[2] && sq[3] == cardsP2[3]){    ##SEQUENCE = PLAYER2???
      c2 = c2+1
      
      sq[1] = deck[k+1]
      sq[2] = deck[k+2]
      sq[3] = deck[k+3]
      k = k+3
    }
    else {
    
    #I go ahead with the cards 
    sq[1] = sq[2]
    sq[2] = sq[3]
    sq[3] = deck[k]
    k = k+1
    }
  }   
  #Ant the winne is.....?
  if (c1>c2){
    winP1=winP1+1}
  if(c2>c1){
    winP2=winP2+1}
  if(c2==c1){
    draw=draw+1}
}
cat('P_player1 = ',winP1/(winP1+winP2+draw),'\nP_player2 = ', winP2/(winP1+winP2+draw),'\nP_draw = ',
draw/(winP1+winP2+draw))
```
The probability of the Player2 is increased a lot.

## Video
This trick is amazing and it work. 
The quality of the video is more or less at 5p buuut...those cards and that song...

##  Why this happen

In general, if the Player2 takes that particular sequence of cards, depending on the one taken by the Player1, he anticipates it in the victory.

In fact, Player1 has the chance to win when his cards 1 and 2 appear, but he has to wait for the next hand to get a chance to win.
On the other hand, when these two cards appear, Player2 has already had the chance to win, this is because those two cards are the last of his patterns. 

In the particular case of last simulation with the pattern Player1 = (R, R, B) and Player2 = (B, R, R), Player1 can win ONLY if the firss two cards, when you turn them, are R.

# Part 2

## Observation 1
We must repeat N times an algorithm that generate each time a new matrix \( L \in \mathbb{R}^{p \times d} \).
We moltiply theese matrices each time for the same vector \( x \in \mathbb{R}^d \).
This means that we always choose the same columns, given by non-zeros elements in \( x \).

At the end we choose at most \(n\) columns of \(L\), because our imput is a vector \( (i_1,i_2, \dots ,i_n) \in \mathbb{R}^n\) with elements \( i_j \in (1,d)\) not necessarily different.
So there are at least \(d-n\) superflous \(L\) columns.

To save mamory space, do a good simulation and save my pc from the fire...we decide to do the follow thing: we generate a matrix \(L' \in \mathbb{R}^{p \times d}\). Now, since we thake at most \(n\) columns, each new value \(i_k\) in streaming select a column of \(L'\). The fist element \(i_1\) select the first column of \(L'\), to explain we call this column \(L'_1 \in \mathbb{R}^p\), and we make \(L'_1 + y\). When the \(i_j\) element come, if it is different from the previus elements we take \(L'_k + y\), otherwise we select the column corresponding to that value.

In this way we can generate more \(L\).

## Observation 2
We now that this process work ONLY for this simulation for a fixed \(x\). But the purpos of this exercise is verify the equation 1 in this particular case.

## Observation 3
We now that for make this process we need to store the value of \(i_k\) like the 'name' of the columns of \(L\), like for a data frame.

One of the request is not to do it so...there is also a different code where we generate \( L \in \mathbb{R}^{p \times d}\) and without saving \(i_k\) we select the \(k^{th}\) column of \(L\) and we add it to \(y\).

Of course it is, IN THIS CASE, the same thing. 


## Algorithm with \( L \in \mathbb{R}^{p \times n}\)
Starting with declare our parameters, the counter for the success of equation 1 and a Vector_d with element from 1 up to d.
 

```{r }
N = 5000
n = 100
d = 100000
epsilon = 0.4
p = as.integer(log(n)/epsilon^2)
counter = 0
Vector_d = c(1:d)

```
Since we need to know the \( \|x\| \) we need store \(x\) one time and make his norm. We also inizialize the vector that contain the norms of \(y\).

Note that the seed is a function of \(i\) and \(n\).

```{r }
x_double_check = rep.int(0, d)
for (i in 1:n){
  set.seed(i*12 + n)
  i_k = sample(Vector_d, 1, replace=TRUE)
  x_double_check[i_k] = x_double_check[i_k] + 1   
}
norms_x = norm(x_double_check, type = '2')
norms_y = numeric(N)
```
Now is possible to start with the loop on \(N\).


```{r }
for (j in 1:N) {
  y = rep.int(0, p)
  set.seed(j*52+145)
  L = rnorm(n*p, mean = 0, sd = sqrt(1/p))
  L = matrix(L, nrow = p, ncol = n)
  L = data.frame(L)
  
  #the name of the columns is equal to the value of i_k
  #now there aren't i_k so it is an empty vector
  column_name_L = c()
  for (i in 1:n){
    set.seed(i*12 + n)
    i_k = sample(Vector_d, 1, replace=TRUE)
    if (match(i_k,column_name_L, nomatch = n+1) == n+1){
      column_name_L = append(column_name_L, i_k)
      col_index_L = length(column_name_L)
    }
    else {
      col_index_L = match(i_k,column_name_L)
    }
    for (k in 1:p){
      y[k] = y[k] + L[k, col_index_L]
    }
  }
  norms_y[j] = norm(y, type = '2')
  if (norms_x*(1-epsilon) < norms_y[j] && norms_y[j] < norms_x*(1+epsilon)) {
    counter = counter + 1
  }
}

```

Now we have a vector with \(N\) norms of \(y\), one for each run.
So we can make an histogram


```{r }
data.frame(iter = c(1:N), 
           x_norm = norms_x, 
           y_norm = norms_y) %>% 
  melt(id = "iter") %>% 
  ggplot() +
  geom_histogram(aes(x = value), bins = 35 ) +
  facet_grid(variable~.,  scales = "free_y") +
  geom_vline(xintercept = norms_x*(1-epsilon) ) +
  geom_vline(xintercept = norms_x*(1+epsilon) )

```

This is the distibution of all \(\|y\|\), the two vertical lines are the values of \( (1-\epsilon)\|x\| \) and \((1+\epsilon)\|x\|\). 
This run is for a fixed value of \(\epsilon\).

## Play around with different values of d, n, \(\epsilon\) and p
Given the previus algorithm, the same is for the algorithm at the end when we consider the huge matrix (it is only slower), we can change the value of the different parameters and see what append.


#### Fixing n and the formula of p
Now we start with the follow values:

```{r}
d = 10000
N = 1000
n = 100
epsilon = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
p = as.integer(log(n)/epsilon^2)
```

Now running the previus algorithm for each value of \(\epsilon\) we obtain the follow plot of the value of \(\|y\|\) in function of \(\epsilon\).

```{r}
prob_of_success = c(0.997, 0.998, 1,0.997 ,0.994, 0.999, 0.998, 0.995)
mean_norms_y = c(9.973812, 9.886229, 9.910172 ,9.937826, 9.767758, 9.756511, 9.534825, 9.496315)
std_norms_y = c(0.6626884, 0.9956172, 1.288591 ,1.640828, 2.034756, 2.289638, 2.585135, 3.123317)

plot(epsilon, mean_norms_y,
    ylim=range(c(mean_norms_y-std_norms_y, mean_norms_y+std_norms_y)),
    pch=19, xlab="Epsilon", ylab="Mean +/- SD of the norm of y",
    main="Norm of y in function of epsilon"
)
arrows(epsilon, mean_norms_y-std_norms_y, epsilon, mean_norms_y+std_norms_y, length=0.05, angle=90, code=3)

```

We can look such as the mean of \(\|y\|\) is more or less constan in function of \(\epsilon\) and the standar deviation coming bigger, but also the confident intervall coming bigger. In fact we had fixed \(p = \frac{\ln{n}}{\epsilon ^2} \). This is the important part, changing \(epsilon\) or \(d\), if \(p = \frac{\log{n}}{\epsilon^2}\) we have, for the Equation 1, that:

\( P[(1-\epsilon)\|x\| < \|y\|<(1+\epsilon)\|x\|] \geq 1-e^{-\epsilon^2 p} =1-e^{-\ln{n}} \) is always true.
If we plot theese two probability we can see than this realation is true.

```{r}
plot(epsilon, prob_of_success,
     ylim=range(c(0.97,1.02)),
    pch=19, xlab="epsilon", ylab=" Prob ",
    main="Probability in function of epsilon") + 
  lines(epsilon,  (1 - exp(-p*epsilon^2)))

```

The line is the value of probability of the formula \(1-e^{-\epsilon^2 p}\).

If we change only the value of \(d\) we obtain the follow thing:

```{r}
d = c(10, 10^2, 10^3, 10^4, 10^5, 10^6)
N = 1000
n = 100
epsilon = 0.4
p = as.integer(log(n)/epsilon^2)


prob_of_success = c(0.997, 0.999,0.999 ,1 ,1,1)
mean_norms_y = c(32.50593, 13.55029,10.41006, 9.910172,9.910172, 9.910172)
std_norms_y = c(4.379836, 1.837343,1.356187,1.288591,1.288591, 1.288591)

plot(d, mean_norms_y, log="x",
    ylim=range(c(mean_norms_y-std_norms_y, mean_norms_y+std_norms_y)),
    pch=19, xlab="d", ylab="Mean +/- SD of the norm of y",
    main="Norm of y in function of d"
)
arrows(d, mean_norms_y-std_norms_y, d, mean_norms_y+std_norms_y, length=0.05, angle=90, code=3)
```
For small value of \(d\) the norm \(\|y\|\) is closed to the norm of \(\|x\|\) so the Johnson-Lindenstrauss lemma is always true.

For big value of \(d\) we have \(\|x\| \rightarrow \sqrt{n}\) and \(\|y\|\) is closed to this value.

If we plot, such as for the previus case this realtion \( P[(1-\epsilon)\|x\| < \|y\|<(1+\epsilon)\|x\|] \) and \(1-e^{-\epsilon^2 p} \) we can see that is always true the relation bethween them.

```{r}
epsilon = c(0.4,0.4,0.4,0.4,0.4,0.4)
plot(d, prob_of_success, log = 'x',
    ylim=range(c(0.985,1.005)),
    pch=19, xlab="d", ylab=" Prob ",
    main="Probability in function of d") + 
  lines(d,  (1 - exp(-p*epsilon^2)))
```

The relation is always true but for huge d is stronger.

#### Fixing d and \(epsilon\)

Now we are going to see what happen if, for fixed d and \(epsilon\), we change n and p.
```{r}
d = 10000
N = 1000
n = 100
epsilon = 0.4
p = c(as.integer(0.2/epsilon^2),
      as.integer(0.5/epsilon^2),
      as.integer(1.0/epsilon^2),
      as.integer(2.0/epsilon^2),
      as.integer(3.0/epsilon^2),
      as.integer(4.0/epsilon^2),
      as.integer(5.0/epsilon^2))
```

We are going to take walue arround \(\log{n}\) and see what happen.

```{r}
prob_of_success = c(0.373,0.665, 0.816, 0.954, 0.990 ,0.996, 0.999)
mean_norms_y = c(8.026258, 9.24131, 9.548311, 9.767758 ,9.937826, 9.923518, 9.984725)
std_norms_y = c(6.128972, 3.890057, 2.821178, 2.034756 ,1.640828, 1.436265, 1.257684)

plot(p, mean_norms_y,
    ylim=range(c(mean_norms_y-std_norms_y, mean_norms_y+std_norms_y)),
    pch=19, xlab="p", ylab="Mean +/- SD of the norm of y",
    main="Norm of y in function of p"
)
arrows(p, mean_norms_y-std_norms_y, p, mean_norms_y+std_norms_y, length=0.05, angle=90, code=3)

```

But the crucial part is the follow 

```{r}
plot(p, prob_of_success,
    pch=19, xlab="p", ylab=" Prob ",
    main="Probability in function of p") + 
  lines(p,  (1 - exp(-p*epsilon^2)))

```
The probability gets bigger if p gets bigger, for value of \(p \sim \frac{\log{n}}{\epsilon ^2} \), or bigger, the probability is huge.

If we fix p at some value and we change only n, when the relation bethwen p and \(\log{n}\) is true this mean that the \(P\) in the equation 1 become bigger.



## Goal

At the beginig we want a specific value of \(\epsilon\), a specific intercall arround the \(\|x\|\), so we pick a fixed value.
What now changes is the length of the input data n. So the real asymptotic dependence of p is given only by n.

On the other hand, we can't generate every single time, for each value of \(n\), a new matrix \(L \in \mathbb{R}^{p \times d}\), because for a network switch should be \(d \approx 10^9\), or something like this.
So if we want generate only one time this matrix, and store it, we need to know \(p\) so we need to know more or less a mean for \(n\).
Also because if we read the data on streaming we can't konw the size of \(n\), and we should change \(L\) eache time.

this average value for \(n\) could be given by the speed of the network or by the flow of people, so for a fixed \(\epsilon\) if we improve the network, the speed will increase and we should generate a new matrix. 

So at the end the answers is yes, we have achieved our goal because \(\epsilon\) is a fixed value.


## Algorithm with \( L \in \mathbb{R}^{p \times d}\)

Is the same but in this case we don't save any value but we generate an huge matrix.
```{r, eval=FALSE}
N = 1000
n = 100
d = 100000
epsilon = 0.4
p = as.integer(log(n)/epsilon^2)
counter = 0

# I just fix x to compute the norm
x_double_check = rep.int(0, d)
for (i in 1:n){
  set.seed(i*124 + n)
  i_k = sample(c(1:d), 1, replace=TRUE)
  x_double_check[i_k] = x_double_check[i_k] + 1   
}

norms_x = norm(x_double_check, type = '2')
norms_y = numeric(N)

for (j in 1:N) {
  y = rep.int(0, p)
  set.seed(j*52+1457)
  L = rnorm(d*p, mean = 0, sd = sqrt(1/p))
  L = matrix(L, nrow = p, ncol = d)
  L = data.frame(L)
  for (i in 1:n){
    set.seed(i*124 + n)
    i_k = sample(c(1:d), 1, replace=TRUE)
    for (k in 1:p){
      y[k] = y[k] + L[k, i_k]
    }
  }
  norms_y[j] = norm(y, type = '2')
  
  if (norms_x*(1-epsilon) < norms_y[j] && norms_y[j] < norms_x*(1+epsilon)) {
    counter = counter + 1
  }
}

data.frame(iter = c(1:N), 
           x_norm = norms_x, 
           y_norm = norms_y) %>% 
  melt(id = "iter") %>% 
  ggplot() +
  geom_histogram(aes(x = value), bins = 30) +
  facet_grid(variable~.)

```


##### Note
We speak with Anil Keswani, who helped us make the code for the histogram and we helped him to understand the relation between \(p\) and \(\epsilon\).
